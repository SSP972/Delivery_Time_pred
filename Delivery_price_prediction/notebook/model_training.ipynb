{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Enginneering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all required library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from math import radians, cos, sin, asin, acos, sqrt, pi\n",
    "from geopy import distance\n",
    "from geopy.geocoders import Nominatim\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "from statistics import  mode\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('/config/workspace/Delivery_price_prediction/notebook/data/finalTrain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clened=pd.read_csv('/config/workspace/Delivery_price_prediction/notebook/data/Final_Raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting independant and dependant features \n",
    "df.drop([                'ID', \n",
    "                'Delivery_person_ID'],inplace=True,axis=1)\n",
    "X=df.drop('Time_taken (min)',axis=1)\n",
    "y=df['Time_taken (min)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categories for ordinal encoding\n",
    "Weather_conditions_ODE=['Sunny','Cloudy','Windy','Fog', 'Stormy', 'Sandstorms' ]\n",
    "Road_traffic_density_ODE=['Low', 'Medium', 'High', 'Jam']\n",
    "Type_of_vehicle_ODE=['bicycle', 'electric_scooter', 'scooter', 'motorcycle']\n",
    "Festival_ODE=['No','Yes']\n",
    "\n",
    "#Categories for One Hot encoding\n",
    "OHE_Cat_City=['Metropolitian', 'Urban', 'Semi-Urban']\n",
    "OHE_Cat_type_orders=['Snack', 'Meal', 'Drinks', 'Buffet']\n",
    "\n",
    "#Column Transformation\n",
    "num_CT=['Delivery_person_Age', 'Delivery_person_Ratings','Vehicle_condition']\n",
    "ordinal_CT=['Weather_conditions', 'Road_traffic_density','Type_of_vehicle', 'Festival']\n",
    "OHE_CT=['City','Type_of_order']\n",
    "time_CT=['Time_Orderd', 'Time_Order_picked']\n",
    "\n",
    "\n",
    "drop_list_pipe=['Restaurant_latitude',\n",
    "                'Restaurant_longitude', \n",
    "                'Delivery_location_latitude',\n",
    "                'Delivery_location_longitude',\n",
    "                'Time_Orderd', \n",
    "                'Time_Order_picked', \n",
    "                'Order_Date',\n",
    "\n",
    "               ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer ## HAndling Missing Values\n",
    "from sklearn.preprocessing import StandardScaler # HAndling Feature Scaling\n",
    "from sklearn.preprocessing import OrdinalEncoder # Ordinal Encoding\n",
    "from sklearn.preprocessing import OneHotEncoder # One Hot Encoding\n",
    "## pipelines\n",
    "from sklearn.pipeline import Pipeline,FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance calculator\n",
    "\n",
    "def calculate_spherical_distance(lat1, lon1, lat2, lon2, r=6371):\n",
    "    \n",
    "    # Convert degrees to radians\n",
    "    coordinates = lat1, lon1, lat2, lon2\n",
    "    # radians(c) is same as c*pi/180\n",
    "    phi1, lambda1, phi2, lambda2 = [\n",
    "        radians(c) for c in coordinates\n",
    "    ]  \n",
    "    \n",
    "    # Apply the haversine formula\n",
    "    a = (np.square(sin((phi2-phi1)/2)) + cos(phi1) * cos(phi2) * \n",
    "         np.square(sin((lambda2-lambda1)/2)))\n",
    "    d = 2*r*asin(np.sqrt(a))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_minutes(x):\n",
    "    if isinstance(x, str) and \":\" in x:\n",
    "        return float(x.split(\":\")[0]) * 60 + (float(x.split(\":\")[1]))\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def get_pickup_time(df):\n",
    "    df['Time_Order_picked'].apply(time_to_minutes)\n",
    "    df['Time_Orderd'].apply(time_to_minutes)\n",
    "    df['pickup_time']=df['Time_Order_picked']-df['Time_Orderd']\n",
    "    df.drop(['Time_Order_picked','Time_Orderd'],axis=1,inplace=True)\n",
    "    return df\n",
    "\n",
    "# Pipeline for time columns\n",
    "time_pipeline = Pipeline([\n",
    "    ('time_conversion', FunctionTransformer(get_pickup_time))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distance Transformation\n",
    "distance_pipeline = Pipeline([\n",
    "    ('distance', FunctionTransformer(lambda x: x.assign(Distance=[round(calculate_spherical_distance(*row), 2) \n",
    "    for row in x[['Restaurant_latitude', 'Restaurant_longitude', 'Delivery_location_latitude', 'Delivery_location_longitude']].values])))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Pipeline for date column\n",
    "date_pipeline = Pipeline([\n",
    "    ('extract_month', FunctionTransformer(lambda x: x.assign(Order_Month=x['Order_Date'].apply(lambda y: int(y.split(\"-\")[1]))))),\n",
    "    ('extract_day', FunctionTransformer(lambda x: x.assign(Order_Day=x['Order_Date'].apply(lambda y: int(y.split(\"-\")[0])))))\n",
    "])\n",
    "\n",
    "#Pipeline for frequent values handling \n",
    "frequncy_of_delivery=Pipeline([\n",
    "    ('imputer',SimpleImputer(strategy='most_frequent')),\n",
    "    ('scaler',StandardScaler())\n",
    "])\n",
    "# Numerical Pipeline\n",
    "num_pipeline=Pipeline(\n",
    "    steps=[\n",
    "   \n",
    "    ('imputer',SimpleImputer(strategy='mean')),\n",
    "    ('scaler',StandardScaler())\n",
    "        \n",
    "        ] \n",
    "                    )\n",
    "# Categorical Pipeline\n",
    "cat_pipeline_ODE =Pipeline(\n",
    "    steps=[\n",
    "    \n",
    "    ('imputer',SimpleImputer(strategy='most_frequent')),\n",
    "    ('ordinalencoder',OrdinalEncoder(categories=[Weather_conditions_ODE,Road_traffic_density_ODE,Type_of_vehicle_ODE,Festival_ODE])),\n",
    "    ('scaler',StandardScaler())\n",
    "    \n",
    "    ]\n",
    "                    )\n",
    "cat_pipeline_OHE=Pipeline(\n",
    "    steps=[\n",
    "        ('imputer',SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehotencoder',OneHotEncoder(categories=[OHE_Cat_City,OHE_Cat_type_orders])),\n",
    "        ('scaler',StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "preprocessor=ColumnTransformer([\n",
    "# ('time_pipeline', time_pipeline,),\n",
    "# ('date_pipeline', date_pipeline,),\n",
    "('num_pipeline',num_pipeline,num_CT),\n",
    "('cat_pipeline_ODE',cat_pipeline_ODE,ordinal_CT),\n",
    "('cat_pipeline_OHE',cat_pipeline_OHE,OHE_CT),\n",
    "('Frequency_match',frequncy_of_delivery,[ 'multiple_deliveries'])\n",
    "],remainder='passthrough')\n",
    "\n",
    "drop_non_essential=Pipeline([\n",
    "    ('drop_cols', FunctionTransformer(lambda x: x.drop(drop_list_pipe, axis=1)))\n",
    "])\n",
    "# Combine pipelines\n",
    "full_pipeline = Pipeline([\n",
    "    ('distance_preprocessing', distance_pipeline),\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('Drop_non_essential', drop_non_essential)\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_pipeline.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.30,random_state=30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Engineering\n",
    "X_train=pd.DataFrame(preprocessor.fit_transform(X_train),columns=preprocessor.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=pd.DataFrame(preprocessor.transform(X_test),columns=preprocessor.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Training\n",
    "\n",
    "from sklearn.linear_model import LinearRegression,Lasso,Ridge,ElasticNet\n",
    "from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression=LinearRegression()\n",
    "regression.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def evaluate_model(true, predicted):\n",
    "    mae = mean_absolute_error(true, predicted)\n",
    "    mse = mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(mean_squared_error(true, predicted))\n",
    "    r2_square = r2_score(true, predicted)\n",
    "    return mae, rmse, r2_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train multiple models\n",
    "\n",
    "models={\n",
    "    'LinearRegression':LinearRegression(),\n",
    "    'Lasso':Lasso(),\n",
    "    'Ridge':Ridge(),\n",
    "    'Elasticnet':ElasticNet()\n",
    "}\n",
    "trained_model_list=[]\n",
    "model_list=[]\n",
    "r2_list=[]\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model=list(models.values())[i]\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    #Make Predictions\n",
    "    y_pred=model.predict(X_test)\n",
    "\n",
    "    mae, rmse, r2_square=evaluate_model(y_test,y_pred)\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "\n",
    "    print('Model Training Performance')\n",
    "    print(\"RMSE:\",rmse)\n",
    "    print(\"MAE:\",mae)\n",
    "    print(\"R2 score\",r2_square*100)\n",
    "\n",
    "    r2_list.append(r2_square)\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
